{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from code.text_cleaning import text_process_nltk\n",
    "from code.data_preparation import get_cleaned_doc_from_question\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../Data/\"\n",
    "QUESTION_COL = \"Questions → Title\"\n",
    "RESPONSE_COL = \"Response Text\"\n",
    "TOKEN_COL = \"tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"liste_des_reponses_aux_questions_ouvertes_par_consultation_2023-11-02T10_21_31.386925747Z.csv\"\n",
    "filename_with_demo = \"reponses_aux_questions_ouvertes_croisees_avec_les_donnees_demo_2023-11-02T13_09_36.480435917Z.csv\"\n",
    "df = pd.read_csv(DATA_FOLDER + filename)\n",
    "df_demo = pd.read_csv(DATA_FOLDER + filename_with_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions existantes\n",
    "df[QUESTION_COL].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question = 'Avez-vous des propositions pour financer la transition écologique ? C’est la dernière question !'\n",
    "# question = 'Quelle est pour vous la mesure la plus importante pour réussir la transition écologique ? C’est la dernière question, partagez-nous toutes vos idées !'\n",
    "# question_short = \"transition_ecologique_no_short_ans\"\n",
    "question = 'Quelles sont vos autres propositions pour lutter contre les violences faites aux enfants ?'\n",
    "question_short = \"solutions_violence_enfants\"\n",
    "df_filtered = get_cleaned_doc_from_question(df, QUESTION_COL, RESPONSE_COL, question)\n",
    "X = df_filtered[df_filtered[\"response_size\"] >= 5][\"cleaned_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../data/francetransfert-2628211345/MDPH-verbatims_MDU_positifs.csv\"\n",
    "df_nico = pd.read_csv(filepath, sep=\";\")\n",
    "df_nico = df_nico.dropna(axis=0)\n",
    "question_short = \"MDPH_MDU_positif\"\n",
    "X = df_nico[\"Satis_plus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from code.topic_dataviz import create_wordcloud_from_topic\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Histogramme, des mots par topic\n",
    "# TODO: Score d'incertitude\n",
    "# Essayer sans passer par résumé de chaque échantillon\n",
    "# Créer 5 titres et agréger pour réduire le bruit\n",
    "# Check repetition_penalty param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_bertopic_model(X: pd.Series)-> (BERTopic, pd.DataFrame):\n",
    "    # Remove stopwords\n",
    "    vectorizer_model = CountVectorizer(stop_words=stopwords.words(\"french\"), strip_accents=\"ascii\")\n",
    "    \n",
    "    nr_topics = 10\n",
    "    if True:\n",
    "        topic_model = BERTopic(vectorizer_model=vectorizer_model, nr_topics=nr_topics, language=\"french\")\n",
    "    else:\n",
    "        n_docs = round(X.size * 0.01)\n",
    "        topic_model = BERTopic(vectorizer_model=vectorizer_model, min_topic_size=n_docs, language=\"french\")\n",
    "    # Reduce frequent word importance\n",
    "    #ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "    #topic_model = BERTopic(ctfidf_model=ctfidf_model, language=\"french\")\n",
    "     \n",
    "    topics = topic_model.fit_transform(X)\n",
    "    return topic_model, topics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bert, custom_topics = get_custom_bertopic_model(X)\n",
    "custom_bert.save(\"../data/topic_modeling/\" + question_short + \"/bertopic_model/\", serialization=\"safetensors\", save_ctfidf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bert.generate_topic_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom_bert.visualize_heatmap()\n",
    "custom_bert.visualize_topics()\n",
    "#custom_bert.visualize_term_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bert.hierarchical_topics(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bert.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_infos = custom_bert.get_document_info(X)\n",
    "#docs_with_topics[docs_with_topics[\"Topic\"] == 2]\n",
    "doc_infos.loc[0][\"Representative_Docs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pour récupérer les doc des données trop petites\n",
    "# removed_answers = df_filtered[df_filtered[\"response_size\"] < 5][\"cleaned_text\"]\n",
    "# removed_answers\n",
    "# custom_bert.\n",
    "# custom_bert.transform(list(removed_answers))\n",
    "# custom_bert.get_document_info(removed_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_infos.Topic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_distribution(doc_infos: pd.DataFrame):\n",
    "    answers_per_topic = doc_infos.groupby(\"Topic\").agg(answers=(\"Document\", \"count\")).reset_index()\n",
    "    answers_per_topic[\"percentage\"] = answers_per_topic[\"answers\"] / answers_per_topic[\"answers\"].values.sum() * 100\n",
    "    return answers_per_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_per_topic = get_topic_distribution(doc_infos)\n",
    "answers_per_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs_from_topic(doc_infos: pd.DataFrame, topic: int):\n",
    "    representatives = doc_infos[doc_infos[\"Topic\"] == topic].copy()\n",
    "    print(\"Taille du topic : \", len(representatives.index), \" documents\")\n",
    "    #docs_with_topics[\"Representative_document\"]\n",
    "    return representatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization functions\n",
    "def get_topic_histogram(bertopic: BERTopic, topic: int):\n",
    "    bertopic.visualize_barchart()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"../data/topic_modeling/\" + question_short + \"/\"\n",
    "save_path = save_folder + \"doc_infos.csv\"\n",
    "doc_infos.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TFT5ForConditionalGeneration, T5Tokenizer, pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from random import sample\n",
    "\n",
    "\n",
    "def get_tokenizer(t5=True):\n",
    "    if t5:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "        #tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/camembert2camembert_shared-finetuned-french-summarization\", padding_side='left')\n",
    "    else: \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/mT5_multilingual_XLSum\")\n",
    "        #tokenizer = AutoTokenizer.from_pretrained(\"moussaKam/barthez\")\n",
    "        #tokenizer = AutoTokenizer.from_pretrained(\"moussaKam/barthez-orangesum-abstract\")\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def get_summarizer_pipeline(tokenizer, t5=True):\n",
    "    if t5:\n",
    "        language_model = TFT5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "        summarizer = pipeline(\"summarization\", model=language_model, tokenizer=tokenizer, framework=\"tf\")\n",
    "        #summarizer = pipeline(\"summarization\", model=\"mrm8488/camembert2camembert_shared-finetuned-french-summarization\", tokenizer=tokenizer, framework=\"tf\")\n",
    "\n",
    "\n",
    "    else:\n",
    "        summarizer = pipeline(\"summarization\", model=\"csebuetnlp/mT5_multilingual_XLSum\", tokenizer=tokenizer)\n",
    "        #summarizer = pipeline(\"summarization\", model=\"moussaKam/barthez\", tokenizer=tokenizer)\n",
    "        #summarizer = pipeline(\"summarization\", model=\"moussaKam/barthez-orangesum-abstract\", tokenizer=tokenizer)\n",
    "    return summarizer\n",
    "\n",
    "\n",
    "def get_headline_tokenizer(t5):\n",
    "    headline_tokenizer = T5Tokenizer.from_pretrained(\"Michau/t5-base-en-generate-headline\")\n",
    "    return headline_tokenizer\n",
    "\n",
    "\n",
    "def get_headline_generator(t5=True, model_name=\"\"):\n",
    "    if True: \n",
    "        headline_generator = TFT5ForConditionalGeneration.from_pretrained(\"Michau/t5-base-en-generate-headline\")\n",
    "    else:\n",
    "        #headline_generator = AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/mT5_multilingual_XLSum\")\n",
    "        headline_generator = AutoModelForSeq2SeqLM.from_pretrained(\"moussaKam/barthez-orangesum-title\")\n",
    "    return headline_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_list_from_answers(answers: list[str], summarizer, tokenizer):\n",
    "    summary_list = []\n",
    "    current_token_length = 0\n",
    "    max_token_length = 500 # anciennement 512\n",
    "    #WHITESPACE_HANDLER = lambda k: re.sub('\\\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "    for answer in sample(answers, k=len(answers)):\n",
    "        max_length = min(150, max(10, len(tokenizer.encode(answer))))\n",
    "        summary = summarizer(answer, min_length=10, max_length=max_length)[0][\"summary_text\"]\n",
    "        current_token_length += len(tokenizer.encode(summary))\n",
    "        if current_token_length >= max_token_length:\n",
    "            break\n",
    "        summary_list.append(summary)\n",
    "    return summary_list\n",
    "\n",
    "\n",
    "def get_summary_list_from_answers_with_answer_sum(answers: list[str], summarizer, tokenizer):\n",
    "    summary_list = []\n",
    "    current_token_length = 0\n",
    "    max_token_length = 500 # anciennement 512\n",
    "    min_token_length = 100\n",
    "    to_summarize = \"\"\n",
    "    #WHITESPACE_HANDLER = lambda k: re.sub('\\\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "    for answer in sample(answers, k=len(answers)):\n",
    "        to_summarize = to_summarize + answer + \". \"\n",
    "        answer_size = len(tokenizer.encode(to_summarize))\n",
    "        print(str(answer_size) + \" \" + to_summarize)\n",
    "        if answer_size <= min_token_length: \n",
    "            continue\n",
    "        max_length = min(150, max(10, int(answer_size/2)))\n",
    "        to_summarize = to_summarize.replace(\"..\", \",\")\n",
    "        summary = summarizer(to_summarize, min_length=10, max_length=max_length)[0][\"summary_text\"]\n",
    "        print(\"to_summarize: \", to_summarize)\n",
    "        print(\"summary: \", summary)\n",
    "        to_summarize = \"\"\n",
    "        current_token_length += len(tokenizer.encode(summary))\n",
    "        if current_token_length >= max_token_length:\n",
    "            break\n",
    "        summary_list.append(summary)\n",
    "    return summary_list\n",
    "\n",
    "\n",
    "def get_summary_of_samples(answers: list[str], summarizer, tokenizer):\n",
    "    summary_list = []\n",
    "    current_token_length = 0\n",
    "    max_token_length = 500 # anciennement 512\n",
    "    min_token_length = 200\n",
    "    to_summarize = \"summarize: \"\n",
    "    for answer in sample(answers, k=len(answers)):\n",
    "        to_summarize = to_summarize + answer + \". \"\n",
    "        answer_size = len(tokenizer.encode(to_summarize))\n",
    "        if answer_size <= min_token_length: \n",
    "            continue\n",
    "        max_length = min(150, max(10, int(answer_size/2)))\n",
    "        to_summarize = to_summarize.replace(\"..\", \".\")\n",
    "        summary = summarizer(to_summarize, min_length=10, max_length=max_length, num_beams=5)[0][\"summary_text\"]\n",
    "        print(to_summarize)\n",
    "        print(\"summary: \", summary)\n",
    "        to_summarize = \"summarize: \"\n",
    "        current_token_length += len(tokenizer.encode(summary))\n",
    "        if current_token_length >= max_token_length:\n",
    "            break\n",
    "        summary_list.append(summary)\n",
    "    return summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_topic_label(answers: list[str], summarizer, tokenizer, headline_generator, headline_tokenizer, verbose=False) -> str:\n",
    "    summary_list = get_summary_of_samples(answers, summarizer, tokenizer)\n",
    "    print(summary_list)\n",
    "    encoding = headline_tokenizer.encode(\"titre : \" + \" \".join(summary_list), return_tensors=\"pt\") # test en retirant return_tensors et en mettant titre\n",
    "    output = headline_generator.generate(encoding, max_length=64, num_beams=5, no_repeat_ngram_size=2, repetition_penalty=2.0)\n",
    "    return headline_tokenizer.decode(output[0][1:-1])\n",
    "\n",
    "\n",
    "def get_labels_from_topics(doc_infos, i_range, verbose=False, t5=True, label_per_topic: int=5):\n",
    "    tokenizer = get_tokenizer(t5)\n",
    "    summarizer = get_summarizer_pipeline(tokenizer, t5)\n",
    "    headline_generator = get_headline_generator(t5)\n",
    "    headline_tokenizer = get_headline_tokenizer(t5)\n",
    "    topic_labels = []\n",
    "    for i in range(i_range):\n",
    "        topic_i = get_docs_from_topic(doc_infos, i)\n",
    "        doc_i = topic_i['Document'].values.tolist()\n",
    "        label_options = []\n",
    "        for j in range(label_per_topic):\n",
    "            label = generate_topic_label(doc_i, summarizer, tokenizer, headline_generator, headline_tokenizer, verbose)\n",
    "            label_options.append(label)\n",
    "        print(\"Topic \" + str(i) + \" : \" + \", \".join(label_options))\n",
    "        topic_labels.append(label_options)\n",
    "    return topic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_summary(question, summary_list):\n",
    "    result = \"Question : \" + question + \". Réponse : \" + \" \".join(summary_list)\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_topic_summary(answers: list[str], summarizer, tokenizer, question):\n",
    "    summary_list = get_summary_list_from_answers_with_answer_sum(answers, summarizer, tokenizer)\n",
    "    #formated_summary = format_summary(question, summary_list)\n",
    "    formated_summary = \" \".join(summary_list)\n",
    "    print(formated_summary)\n",
    "    return summarizer(formated_summary, max_length=150)[0][\"summary_text\"]\n",
    "\n",
    "\n",
    "def get_summary_from_topics(doc_infos, i_range, question, t5):\n",
    "    tokenizer = get_tokenizer(t5)\n",
    "    summarizer = get_summarizer_pipeline(tokenizer, t5)\n",
    "    topic_labels = []\n",
    "    for i in range(i_range):\n",
    "        topic_i = get_docs_from_topic(doc_infos, i)\n",
    "        doc_i = topic_i['Document'].values.tolist()\n",
    "        topic_summary = generate_topic_summary(doc_i, summarizer, tokenizer, question)\n",
    "        print(topic_summary)\n",
    "        label = \"Résumé \" + str(i) + \" : \" + topic_summary\n",
    "        print(label)\n",
    "        topic_labels.append(label)\n",
    "    return topic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def measure_similarity_of_topic(topic_labels: list[str], topic_model):\n",
    "    embedding = topic_model.embedding_model.embed(topic_labels)\n",
    "    similarity_matrix = cosine_similarity(embedding)\n",
    "\n",
    "    top_label = topic_labels[np.argmax(np.sum(similarity_matrix, axis=1))]\n",
    "        \n",
    "    # scoring topic\n",
    "    triu_mat = np.triu(similarity_matrix, k=1)\n",
    "    score = np.mean(triu_mat[np.nonzero(triu_mat)])\n",
    "\n",
    "    return similarity_matrix, top_label, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_range = sum(answers_per_topic[\"percentage\"] > 1.5) -1\n",
    "i_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_doc_infos_before_labeling(doc_infos: pd.DataFrame):\n",
    "    filtered_doc_info = doc_infos[doc_infos[\"Probability\"] > 0.70].copy()\n",
    "    filtered_doc_info[\"response_size\"] = filtered_doc_info[\"Document\"].str.split().apply(len)\n",
    "    to_drop = filtered_doc_info[filtered_doc_info[\"response_size\"] < 10]\n",
    "    filtered_doc_info.drop(to_drop.index, inplace = True)\n",
    "    return filtered_doc_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_doc_infos = filter_doc_infos_before_labeling(doc_infos)\n",
    "filtered_doc_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = True\n",
    "label_per_topic = 10\n",
    "topic_labels = get_labels_from_topics(filtered_doc_infos, i_range=i_range, verbose=True, t5=t5, label_per_topic=label_per_topic)\n",
    "for topic in topic_labels:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_json_file(data, filename: str):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "def clean_labels(labels_list: list[list[str]]):\n",
    "    REMOVE_TOKENS = lambda x : re.sub(\"(<pad>)*(</s>)*\", \"\", x)\n",
    "    new_labels_list = []\n",
    "    for labels in labels_list:\n",
    "        new_labels = [REMOVE_TOKENS(x) for x in labels]\n",
    "        new_labels_list.append(new_labels)\n",
    "    return new_labels_list\n",
    "\n",
    "cleaned_labels = clean_labels(topic_labels)\n",
    "write_json_file(cleaned_labels, DATA_FOLDER + \"topic_modeling/\" + question_short + \"/cleaned_labels.json\")\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_similarity_of_topic(topic_labels[1], custom_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_summaries = get_summary_from_topics(doc_infos, i_range=i_range, question=question, t5=t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_n = get_docs_from_topic(filtered_doc_infos, 4)\n",
    "looking_for = \"\"\n",
    "doc_n = topic_n[topic_n['Document'].str.contains(looking_for)][\"Document\"].values\n",
    "doc_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Topic 4 label: {generate_topic_label(doc_n.tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using KeyBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "# Prepare documents \n",
    "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']\n",
    "\n",
    "# Extract keywords\n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(docs)\n",
    "\n",
    "# Create our vocabulary\n",
    "vocabulary = [k[0] for keyword in keywords for k in keyword]\n",
    "vocabulary = list(set(vocabulary))\n",
    "# Then, we pass our vocabulary to BERTopic and train the model:\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model= CountVectorizer(vocabulary=vocabulary)\n",
    "topic_model = BERTopic(vectorizer_model=vectorizer_model)\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.generate_topic_labels(nr_words=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
